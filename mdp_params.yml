# MDP (Markov Decision Process) Parameters
reward_click: 0.2
reward_buy: 1.0
reward_negative: 0
discount_factor: 0.5
neg_samples: 10